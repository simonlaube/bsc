% !TEX root = ../Thesis.tex
\chapter{Resource Management}
Resource Management is an important part when using autonomous devices which only run on low energy. Storage and energy limitations both need to be considered when running a TinySSB node. Some aspects of resource management were already discussed in \cref{sec:fork} and \cref{sec:session}. By reducing the number of feeds for which nodes request packets, energy consumption can be reduced. By being able to delete older feeds or packets, storage usage can be reduced significantly.
However there are still options left that can further reduce computing power and memory usage.

\section{Incoming and Outgoing Packets}
An important part of resource management happens when choosing which outgoing packets to send first and which incoming packets to read first. Some feeds should be considered as more important than others and therefore should be handled first. However it should still be guaranteed that feeds with less importance get allocated some resources as well. To help solve this problem a new priority queue is introduced. One instance of such a queue is created for incoming packets and one for outgoing packets. If a packet reaches a node, it gets appended to the incoming queue. When a packet is ready to be sent out, it is appended to the outgoing queue. A user has to first define a number $n$ of how many different priority classes should exist. Every priority $p_i$ (from $p_0$ to $p_{n - 1}$ gets assigned a certain amount of slots from the total slot count. A slot is not bound to a time or computation limit but represents one packet request from the priority queue. This slot amount is calculated with the following algorithm: \\ 
$slots_p = \lceil (n - p)^{1.5} \rceil$ \\
For $n = 3$ priority classes this would result in 5 slots for $p_0$, 2 slots for $p_1$ and 1 slot for $p_2$ (with a total slot count of 8). This simple algorithm worked well for the use-cases tested (3 and 4 different priority classes) must however be reevaluated if in a later use-case significantly more priority classes are needed. \\
When adding a packet to a queue, the user can give the packet a priority from 0 to $n - 1$ with 0 being the highest and $n-1$ the lowest priority. When requesting packets from a priority queue, packets are returned according to the slots described before. If 8 packets are requested consecutively from the queue, priority 0 is guaranteed to have at least 5 packets returned, priority 1 two packets and priority 3 one packet. However if no packets exist in the queue for a given priority class, the slot gets transferred to the next higher priority class. To further optimize the queue and to avoid redundancy, packets can only be appended if the same packet is not already in the queue. This is a very important feature since one packet request could lead to multiple nodes returning the same packet. By only processing one packet, the computing time and memory usage can be reduced.

\section{Resource Manager Loop}
Scheduling the resource allocation is done in the Resource-Manager-Loop. Its main job is to optimally distribute computing power to four tasks. The first one is specific to the node and includes any computation that the node has to do in order to append data to its own feed. This could be recording the temperature or humidity or any other sensory data and appending it to a feed or tree. If the node only serves as a network node to forward data, this task can be neglected. Secondly it has to handle incoming packets and append them to feeds that the node replicates. Thirdly it has to send want requests for feeds it is replicating and lastly it has to send packets if want requests were being received. After one iteration of the loop has been processed - or in harsh low energy conditions already at places within the loop - the device can decide if it goes to sleep for a certain amount of time (while it still is able to receive packets and append them to the in-queue). In the test cases for this project the nodes slept for 3 seconds before starting the next iteration of the loop. However the focus was not set on energy efficiency. In larger networks, the waiting time for individual nodes can probably be longer to not clog the network and reduce energy consumption.

\section{Central DMX handling}
To improve DMX handling (packet requesting and matching DMX values of incoming packets with the DMX table), this is handled in a central DMX filter class that is managed by the resource manager. This filter handles DMX values in different category groups. Every new value has to be added to a specific category. The number of categories is not limited and the node creates a new category for each feed tree and one for ID feeds. This is done to be able to easily delete or change all DMX values of a tree with a single command. Since for every expected packet there is a corresponding want request, the creation of want packets is also handled in the same class. When sending a want request, the resource manager can directly ask the DMX filter for a want packet and append it to the out-queue. To prevent the node from asking for the same packet multiple times in a short time, the filter only returns the same want packet after a certain time interval has elapsed.